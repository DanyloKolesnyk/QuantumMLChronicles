{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Product State (MPS) with Compression Layer\n",
    "\n",
    "This code implements a training procedure for a Matrix Product State (MPS) model with a compression layer, following the algorithm described in a research paper [Generative Learning of Continuous Data by Tensor Networks](https://arxiv.org/abs/2310.20498). The MPS efficiently models high-dimensional data, and the compression layer reduces the dimensionality of the input data before feeding it into the MPS, improving computational efficiency.\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "- **`contract_mps_except_i` Function**: Contracts the MPS with compressed input data, excluding a specified site.\n",
    "- **`train_compression_layer` Function**: Trains the compression matrices using the Procrustes problem.\n",
    "- **Procrustes Problem**: Solved using Singular Value Decomposition (SVD) to update the compression matrices.\n",
    "\n",
    "In this implementation, we provide detailed explanations and step-by-step computations to facilitate understanding and future modifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `contract_mps_except_i` Function\n",
    "\n",
    "This function computes the vector v_{i,j} for a given sample  x^{(j)} and site i  by contracting the MPS with compressed input data, excluding site i .\n",
    "\n",
    "**Process:**\n",
    "\n",
    "1. **Compress Input Data**: For each site  $n \\neq i$, compress the input data $x_n^{(j)}$ using the compression matrix $U_n$:\n",
    "   \n",
    "   $\\tilde{x}_n^{(j)} = U_n^T x_n^{(j)}$\n",
    "   \n",
    "\n",
    "2. **Contract with MPS Tensors**: Contract each compressed slice with its corresponding MPS tensor over the physical dimension.\n",
    "\n",
    "3. **Sequential Contraction**: Sequentially contract the MPS tensors over the bond dimensions, skipping the contraction over the physical dimension at site i .\n",
    "\n",
    "4. **Final Contraction**: After contracting all sites, the result is a vector $v_{i,j}$ of shape equal to the compressed physical dimension $d$ , representing the MPS-contracted embedding excluding site $i$.\n",
    "\n",
    "\n",
    "This vector $v_{i,j}$ is then used in the training process to update the compression matrix $U_i$ via the Procrustes problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_mps_except_i(mps, U_list, input_data, exclude_index):\n",
    "    \"\"\"\n",
    "    Contracts the MPS with compressed input data excluding site i.\n",
    "    Returns a vector of shape (phys_compressed,) corresponding to v_{i,j}.\n",
    "    \"\"\"\n",
    "    N = len(mps)\n",
    "    # Step 1: Compress all data slices except at the excluded index\n",
    "    compressed_slices = []\n",
    "    for idx in range(N):\n",
    "        if idx != exclude_index:\n",
    "            data_slice = input_data[idx]          # Shape: (physical_dim_data,)\n",
    "            U_i = U_list[idx]                     # Shape: (physical_dim_data, phys_compressed)\n",
    "            compressed_slice = data_slice @ U_i   # Shape: (phys_compressed,)\n",
    "            compressed_slices.append(compressed_slice)\n",
    "        else:\n",
    "            compressed_slices.append(None)  # Placeholder for the excluded index\n",
    "\n",
    "    # Step 2: Contract compressed slices with MPS tensors over the physical dimension\n",
    "    mps_contracted_list = []\n",
    "    for idx in range(N):\n",
    "        mps_tensor = mps[idx]  # Shape: (bond_dim_left, phys_compressed, bond_dim_right)\n",
    "\n",
    "        if idx != exclude_index:\n",
    "            compressed_slice = compressed_slices[idx]  # Shape: (phys_compressed,)\n",
    "            # Contract over the physical dimension (dimension 1)\n",
    "            mps_contracted = torch.tensordot(mps_tensor, compressed_slice, dims=([1], [0]))\n",
    "            # Resulting shape: (bond_dim_left, bond_dim_right)\n",
    "        else:\n",
    "            # Keep the MPS tensor uncontracted over the physical dimension\n",
    "            mps_contracted = mps_tensor  # Shape: (bond_dim_left, phys_compressed, bond_dim_right)\n",
    "\n",
    "        mps_contracted_list.append(mps_contracted)\n",
    "\n",
    "    # Step 3: Sequentially contract MPS tensors over the bond dimensions\n",
    "    result = mps_contracted_list[0]\n",
    "    for idx in range(1, N):\n",
    "        next_tensor = mps_contracted_list[idx]\n",
    "\n",
    "        if idx == exclude_index:\n",
    "            # Contract over bond dimensions\n",
    "            result = torch.tensordot(result, next_tensor, dims=([-1], [0]))\n",
    "            # Resulting shape: (1, phys_compressed, bond_dim_right)\n",
    "        else:\n",
    "            # Contract over bond dimensions\n",
    "            result = torch.tensordot(result, next_tensor, dims=([-1], [0]))\n",
    "            # Resulting shape updates accordingly\n",
    "\n",
    "    # After sequential contractions, result should have shape (1, phys_compressed, 1)\n",
    "    # Squeeze to get (phys_compressed,)\n",
    "    v_i_j = result.squeeze()\n",
    "    return v_i_j  # Shape: (phys_compressed,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Compression Layer (`train_compression_layer` Function)\n",
    "\n",
    "The `train_compression_layer` function trains the compression matrices $\\{ U_i \\}$ using the input data and the MPS.\n",
    "\n",
    "**Algorithm Overview:**\n",
    "\n",
    "For each site $i$ and over multiple epochs:\n",
    "\n",
    "1. **Compute  $u_{i,j}$ and $v_{i,j}$**:\n",
    "   - $u_{i,j} = x_i^{(j)}$: The input feature vector at site $i$ for sample $j$.\n",
    "   - $v_{i,j}$: The MPS-contracted embedding excluding site $i$, computed using `contract_mps_except_i`.\n",
    "\n",
    "2. **Compute Inner Product $c_j$**:\n",
    "   \n",
    "   $c_j = u_{i,j}^T U_i v_{i,j}$\n",
    "\n",
    "3. **Calculate Magnitude and Phase**:\n",
    "   - Magnitude:\n",
    "     \n",
    "     $p_j = |c_j| + \\delta$\n",
    "\n",
    "     where $\\delta$ is a small constant to prevent division by zero.\n",
    "   - Phase:\n",
    "     \n",
    "     $\\phi_j = \\frac{c_j}{p_j}$\n",
    "\n",
    "4. **Accumulate Negative Log-Likelihood Loss**:\n",
    "   \n",
    "   $\\text{NLL Loss} = -\\sum_j \\log(p_j)$\n",
    "\n",
    "5. **Update Compression Matrix $U_i$**:\n",
    "   - Formulate the matrix $B$:\n",
    "     \n",
    "     $B = \\sum_j \\left( p_j^\\epsilon \\phi_j \\right)^{-1} u_{i,j} v_{i,j}^T$\n",
    "     where $\\epsilon$ is a stability parameter adjusted during training.\n",
    "   - Solve the Procrustes problem using SVD to update $U_i$:\n",
    "     \n",
    "     $U_i = U_{\\text{B}} V_{\\text{B}}^T$\n",
    "     where $U_{\\text{B}}$ and $V_{\\text{B}}$ come from the SVD of $B$:\n",
    "     \n",
    "     $B = U_{\\text{B}} \\Sigma_{\\text{B}} V_{\\text{B}}^T$\n",
    "     \n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- The compression matrices $U_i$ are updated to minimize the negative log-likelihood loss.\n",
    "- The use of SVD ensures that $U_i$ remains an isometric (orthogonal) matrix.\n",
    "- The stability parameter $\\epsilon$ is adjusted during training to ensure convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_compression_layer(input_data, mps, U_list, num_tensors, bond_dim, phys_compressed, epochs=5):\n",
    "    \"\"\"\n",
    "    Train the compression layer for an MPS using a set of input data over multiple epochs.\n",
    "    Implements the algorithm as per the provided pseudocode from the paper.\n",
    "    \"\"\"\n",
    "    num_samples = input_data.shape[0]\n",
    "    physical_dim_data = input_data.shape[2]\n",
    "    epsilon = 0.5  # Controls stability, will be adjusted\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_nll_loss = 0\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for tensor_index in range(num_tensors):  # Loop over each site\n",
    "            u_list = []  # Original feature embeddings (u_{i,j})\n",
    "            v_list = []  # MPS-contracted embeddings excluding site i (v_{i,j})\n",
    "            c_list = []  # Inner products c_j\n",
    "            p_list = []  # Magnitudes |c_j|\n",
    "            phi_list = []  # Phases φ_j\n",
    "\n",
    "            for sample_idx in range(num_samples):  # Loop over each sample in the batch\n",
    "                x_j = input_data[sample_idx]       # Shape (N, physical_dim_data)\n",
    "                u_i_j = x_j[tensor_index]          # Shape (physical_dim_data,)\n",
    "\n",
    "                # Compute v_{i,j}\n",
    "                v_i_j = contract_mps_except_i(mps, U_list, x_j, tensor_index)  # Shape (phys_compressed,)\n",
    "\n",
    "                # Compute c_j = u_i_j^T U_i v_i_j\n",
    "                U_i = U_list[tensor_index]  # Shape (physical_dim_data, phys_compressed)\n",
    "                temp = U_i.T @ u_i_j        # Shape (phys_compressed,)\n",
    "\n",
    "                c_j = temp @ v_i_j          # Scalar\n",
    "\n",
    "                p_j = torch.abs(c_j) + 1e-20  # Magnitude\n",
    "                phi_j = c_j / p_j            # Phase\n",
    "\n",
    "                # Store intermediate results\n",
    "                u_list.append(u_i_j)\n",
    "                v_list.append(v_i_j)\n",
    "                c_list.append(c_j)\n",
    "                p_list.append(p_j)\n",
    "                phi_list.append(phi_j)\n",
    "\n",
    "                # Accumulate NLL loss\n",
    "                nll_loss = -torch.log(p_j)\n",
    "                total_nll_loss += nll_loss\n",
    "\n",
    "            # Update U_i using Procrustes problem\n",
    "            # Compute B = Σ_j (p_j^ε φ_j)^{-1} u_{i,j} v_{i,j}^T\n",
    "            B = torch.zeros((physical_dim_data, phys_compressed), dtype=torch.float32)\n",
    "            for j in range(num_samples):\n",
    "                weight = ((p_list[j] ** epsilon) ** (-1)) * phi_list[j]\n",
    "                B += weight.real * torch.outer(u_list[j], v_list[j])\n",
    "\n",
    "            # Perform SVD on B\n",
    "            try:\n",
    "                B_U, _, B_Vh = torch.linalg.svd(B, full_matrices=False)\n",
    "                # Update U_i = B_U @ B_Vh^T\n",
    "                U_i_new = B_U @ B_Vh\n",
    "                U_list[tensor_index] = nn.Parameter(U_i_new)\n",
    "            except Exception as e:\n",
    "                print(f\"SVD failed at tensor index {tensor_index}: {e}\")\n",
    "                continue  # Skip updating this U_i if SVD fails\n",
    "\n",
    "            # Adjust epsilon\n",
    "            epsilon = min(1.0, epsilon + 0.05)\n",
    "            if not torch.isfinite(U_list[tensor_index]).all():\n",
    "                epsilon = max(0.0, epsilon - 0.05)\n",
    "        print(f\"Total NLL Loss after epoch {epoch+1}: {total_nll_loss.item()}\")\n",
    "    return U_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Below is the implementation of the MPS with a compression layer, including the functions and training loop as described. The code follows the algorithm outlined in the previous sections, with detailed comments and explanations.\n",
    "\n",
    "**Note**: The code uses PyTorch for tensor operations and assumes that you have PyTorch installed in your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "phys_compressed = 2  # Compressed dimension d\n",
    "bond_dim = 4         # Bond dimension χ\n",
    "N = 10               # Number of tensors/sites (reduced for simplicity)\n",
    "physical_dim_data = 2  # Original physical dimension D\n",
    "num_samples = 100    # Number of data samples\n",
    "epochs = 15         # Number of epochs for training\n",
    "\n",
    "# Initialize MPS\n",
    "mps = []\n",
    "for i in range(N):\n",
    "    if i == 0:\n",
    "        mps_tensor = torch.randn(1, phys_compressed, bond_dim) / N  # Shape (1, d, χ)\n",
    "    elif i == N - 1:\n",
    "        mps_tensor = torch.randn(bond_dim, phys_compressed, 1) / N  # Shape (χ, d, 1)\n",
    "    else:\n",
    "        mps_tensor = torch.randn(bond_dim, phys_compressed, bond_dim) / N  # Shape (χ, d, χ)\n",
    "    mps.append(mps_tensor)\n",
    "\n",
    "# Initialize U_list\n",
    "# Initialize U_list with QR decomposition of a random matrix\n",
    "U_list = []\n",
    "for _ in range(N):\n",
    "    random_matrix = torch.randn(physical_dim_data, phys_compressed)\n",
    "    q, _ = torch.qr(random_matrix)\n",
    "    U_list.append(nn.Parameter(q))\n",
    "    \n",
    "# Generate input_data using the identity matrix\n",
    "# For simplicity, we'll create samples where each feature vector is an identity vector\n",
    "input_data = torch.zeros(num_samples, N, physical_dim_data)\n",
    "for i in range(num_samples):\n",
    "    for j in range(N):\n",
    "        input_data[i, j] = torch.tensor([1.0, 0.0])  # Use a fixed vector for all features\n",
    "\n",
    "# Train the compression layer over multiple epochs\n",
    "U_list = train_compression_layer(input_data, mps, U_list, N, bond_dim, phys_compressed, epochs=epochs)\n",
    "\n",
    "print(\"Training completed.\")\n",
    "print(\"U_list[0]:\")\n",
    "print(U_list[0].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
